\chapter{FlowPools, Proofs}
\label{appdx:flowpools}

\section{Introduction}

Implementing correct and deterministic parallel programs is challenging. Even
though concurrency constructs exist in popular programming languages to
facilitate the task of deterministic parallel programming, they are often too
low level, or do not compose well due to underlying blocking mechanisms. In this
appendix, we present the detailed proofs of the lock-freedom, and determinism
properties of FlowPools, a deterministic concurrent dataflow abstraction
presented in~\cite{FlowPools}. The detailed proofs for linearizability and
determinism can be found in the companion tech report~\cite{Prokopec12}.

We first provide a summary of the lemmas and theorems introduced in the
associated paper, \emph{FlowPools: A Lock-Free Deterministic Concurrent Dataflow
Abstraction}~\cite{FlowPools}. We then cover definitions and invariants before
moving on to our proof of lock-freedom.

We define the notion of an abstract pool $\mathbb{A} = (elems,
callbacks, seal)$ of elements in the pool, callbacks and the seal
size.
Given an abstract pool, abstract pool operations produce a new
abstract pool.
The key to showing correctness is to show that an abstract pool operation
corresponds to a FlowPool operation-- that is, it produces a
new abstract pool corresponding to the state of the FlowPool after
the FlowPool operation has been completed.

%\begin{lemmatwo}
%For all blocks $b$ reachable from $start$, if $b.index > 0$ at some time $t_0$, then
%$b.array(b.index - 1) \in Elem$ at time $t_0$.
%\end{lemmatwo}

%\begin{lemmatwo}
%For all blocks $b$ reachable from $start$, and for all $x \in b.array$,
%function $x$ goes through and only through the prefix of transitions
%$null \rightarrow cb_1 \rightarrow \dots \rightarrow cb_n \rightarrow elem$, where
%$cb_i \in Terminal$, $i \neq j \Rightarrow cb_i \neq cb_j$ and $elem \in Elem$.
%\end{lemmatwo}

%\begin{lemmatwo}
%We define the following invariants for the FlowPool.
%The reference $current$ is always reachable from $start$.
%There are no cycles in the directed graph of references from $start$.
%Each block $b.array$ is a string of elements, followed by a
%$Terminal$ value, followed by a $null$ or a $Terminal$ value, followed
%by $null$.
%The $b.index$ is $0$ or the preceeding entry in $array$ contains an element.
%
%All writes in all operations retain these invariants.
%\end{lemmatwo}

\begin{figure}

\centering

\begin{minipage}[b]{7 cm}
\begin{alltt}
{\scriptsize
{\internallinenumbers{def create()
  new FlowPool \{
    start = createBlock(0)
    current = start
  \}

def createBlock(bidx: Int)
  new Block \{
    array = new Array(BLOCKSIZE)
    index = 0
    blockindex = bidx
    next = null
  \}

def append(elem: Elem)
  b = READ(current) {\customlabel{read_block}{\LineNumber}}
  idx = READ(b.index) {\customlabel{read_index}{\LineNumber}}
  nexto = READ(b.array(idx + 1)) {\customlabel{read_next}{\LineNumber}}
  curo = READ(b.array(idx)) {\customlabel{read_current}{\LineNumber}}
  if check(b, idx, curo) \{
    if CAS(b.array(idx + 1), nexto, curo) \{ {\customlabel{cas_propagate}{\LineNumber}}
      if CAS(b.array(idx), curo, elem) \{ {\customlabel{cas_append}{\LineNumber}}
        WRITE(b.index, idx + 1) {\customlabel{write_append}{\LineNumber}}
        invokeCallbacks(elem, curo)
      \} else append(elem)
    \} else append(elem)
  \} else \{
    advance()
    append(elem)
  \}

def check(b: Block, idx: Int, curo: Object)
  if idx > LASTELEMPOS return false
  else curo match \{
    elem: Elem =>
      return false
    term: Terminal =>
      if term.sealed = NOSEAL return true
      else \{
        if totalElems(b, idx) < term.sealed
          return true
        else error("sealed")
      \}
    null =>
      error("unreachable")
  \}

def advance()
  b = READ(current)
  idx = READ(b.index)
  if idx > LASTELEMPOS
    expand(b, b.array(idx))
  else \{
    obj = READ(b.array(idx))
    if obj is Elem WRITE(b.index, idx + 1) {\customlabel{write_advance}{\LineNumber}}
  \}

def expand(b: Block, t: Terminal)
  nb = READ(b.next)
  if nb is null \{
    nb = createBlock(b.blockindex + 1)
    nb.array(0) = t
    if CAS(b.next, null, nb) {\customlabel{cas_expand}{\LineNumber}}
      expand(b, t)
  \} else \{
    CAS(current, b, nb) {\customlabel{cas_block}{\LineNumber}}
  \}
}}}
\end{alltt}
\end{minipage}
\begin{minipage}[b]{7 cm}
\begin{alltt}
{\scriptsize
{\internallinenumbers{def totalElems(b: Block, idx: Int)
  return b.blockindex * (BLOCKSIZE - 1) + idx

def invokeCallbacks(e: Elem, term: Terminal)
  for (f <- term.callbacks) future \{
    f(e)
  \}

def seal(size: Int)
  b = READ(current)
  idx = READ(b.index)
  if idx <= LASTELEMPOS \{
    curo = READ(b.array(idx)) {\customlabel{read_seal}{\LineNumber}}
    curo match \{
      term: Terminal =>
        if \(\lnot\)tryWriteSeal(term, b, idx, size)
          seal(size)
      elem: Elem =>
        WRITE(b.index, idx + 1) {\customlabel{write_seal}{\LineNumber}}
        seal(size)
      null =>
        error("unreachable")
    \}
  \} else \{
    expand(b, b.array(idx))
    seal(size)
  \}

def tryWriteSeal(term: Terminal, b: Block,
  idx: Int, size: Int)
  val total = totalElems(b, idx)
  if total > size error("too many elements")
  if term.sealed = NOSEAL \{
    nterm = new Terminal \{
      sealed = size
      callbacks = term.callbacks
    \}
    return CAS(b.array(idx), term, nterm) {\customlabel{cas_seal}{\LineNumber}}
  \} else if term.sealed \(\neq\) size \{
    error("already sealed with different size")
  \} else return true

def foreach(f: Elem => Unit)
  future \{
    asyncFor(f, start, 0)
  \}

def asyncFor(f: Elem => Unit, b: Block, idx: Int)
  if idx <= LASTELEMPOS \{
    obj = READ(b.array(idx)) {\customlabel{read_callback}{\LineNumber}}
    obj match \{
      term: Terminal =>
        nterm = new Terminal \{
          sealed = term.sealed
          callbacks = f \(\cup\) term.callbacks
        \}
        if \(\lnot\)CAS(b.array(idx), term, nterm) {\customlabel{cas_callback}{\LineNumber}}
          asyncFor(f, b, idx)
      elem: Elem =>
        f(elem) {\customlabel{call_callback}{\LineNumber}}
        asyncFor(f, b, idx + 1)
      null =>
        error("unreachable")
    \}
  \} else \{
    expand(b, b.array(idx))
    asyncFor(f, b.next, 0)
  \}
}}}
\end{alltt}
\end{minipage}

\caption{FlowPool operations pseudocode}
\label{f-pseudo}
\end{figure}

\begin{lemmatwo}
Given a FlowPool consistent with some abstract
pool, CAS instructions in lines \ref{cas_propagate}, \ref{cas_expand} and
\ref{cas_block} do not change the corresponding abstract pool.
\end{lemmatwo}

\begin{lemmatwo}
Given a FlowPool consistent with an abstract pool $(elems, cbs,
seal)$, a successful CAS in line \ref{cas_append}
changes it to the state consistent with an abstract pool
$(\{elem\} \cup elems, cbs, seal)$.
There exists a time $t_1 \geq t_0$ at which every callback $f \in
cbs$ has been called on $elem$.
\end{lemmatwo}

\begin{lemmatwo}
Given a FlowPool consistent with an abstract pool $(elems, cbs, seal)$,
a successful CAS in line \ref{cas_callback} changes it
to the state consistent with an abstract pool $(elems, (f, \emptyset)
\cup cbs, seal)$
There exists a time $t_1 \geq t_0$ at which $f$ has been called for
every element in $elems$.
\end{lemmatwo}

\begin{lemmatwo}
Given a FlowPool consistent with an abstract pool $(elems, cbs, seal)$,
a successful CAS in line \ref{cas_seal} changes it to the state
consistent with an abstract pool $(elems, cbs, s)$, where either $seal
= -1 \wedge s \in \mathbb{N}_0$ or $seal \in \mathbb{N}_0 \wedge s = seal$.
\end{lemmatwo}

\begin{theoremtwo}[Safety]
FlowPool operations \verb=append=, \verb=foreach=
and \verb=seal= are consistent with the abstract pool semantics.
\end{theoremtwo}

\begin{theoremtwo}[Linearizable operations]
FlowPool operations \verb=append= and \verb=seal= are linearizable.
\end{theoremtwo}

\begin{lemmatwo}
%[Non-consistency changing instructions]
After invoking a FlowPool operation \verb=append=, \verb=seal= or
\verb=foreach=, if a non-consistency changing CAS instruction in lines
\ref{cas_propagate}, \ref{cas_expand}, or \ref{cas_block} fails, they must have
already been completed by another thread since the FlowPool operation began.
\end{lemmatwo}

\begin{lemmatwo}
%[Consistency changing instructions]
After invoking a FlowPool operation \verb=append=, \verb=seal= or
\verb=foreach=, if a consistency-changing CAS instruction in lines
\ref{cas_append}, \ref{cas_seal}, or \ref{cas_callback} fails, then some thread
has successfully completed a consistency changing CAS after some finite number
of steps.
\end{lemmatwo}

\begin{lemmatwo}
%[Consistency changing operations]
After invoking a FlowPool operation \verb=append=, \verb=seal= or
\verb=foreach=, a consistency changing instruction will be completed after
a finite number of steps.
\end{lemmatwo}

%% I think this is clear -- the theorem follows from the lemma above
%\begin{lemmatwo}
%Assuming some concurrent FlowPool operation is started. If some thread
%completes a consistency changing CAS instruction, then some concurrent
%operation is guaranteed to be completed.
%\end{lemmatwo}

\begin{theoremtwo}[Lock-freedom]
FlowPool operations \verb=append=, \verb=foreach= and \verb=seal= are lock-free.
\end{theoremtwo}


\smallrulenames

\begin{figure}[t]
%\figurebox{
%{\bf Syntax}\medskip

%$\ba{l@{\hspace{2mm}}|@{\hspace{2mm}}l}
%$\ba[t]{l}

\begin{minipage}[b]{5 cm}
$\ba[t]{l@{\hspace{2mm}}l}
t    ::=                                                           & \mbox{terms}              \\
\gap \texttt{create}~p                                   & \mbox{pool creation}  \\
\gap p << v                                                  & \mbox{append}           \\
\gap p~\texttt{foreach}~f                             & \mbox{foreach}           \\
\gap p~\texttt{seal}~n                                  & \mbox{seal}                \\
\gap t_1~;~t_2                                               & \mbox{sequence}        \\
\ea$
\end{minipage}
\begin{minipage}[b]{7 cm}
$\ba[t]{l@{\hspace{2mm}}l}
p \in \set{(vs, \sigma, cbs)~|~vs \subseteq Elem, \sigma \in \set{-1} \cup \mathbb{N}, \\
\text{ } cbs \subset Elem \Rightarrow Unit} \\
v \in Elem \\
f \in Elem \Rightarrow Unit \\
n \in \mathbb{N}
\ea$
\end{minipage}

%\ea$

%}
\caption{Syntax}\label{fig:syntax}
\end{figure}

% \textbf{Determinism.}
% We claim that the FlowPool abstraction is
% \emph{deterministic} in the sense that a program computes the same
% result (which can also be an error) regardless of the interleaving of
% concurrent operations. Here, we give an outline of the determinism
% proof. A complete formal proof can be found in section
% \ref{appendix-determinism}.
%
% The following definitions and the determinism theorem are based on the
% language shown in Figure~\ref{fig:syntax}. The semantics of our core
% language is defined using reduction rules which define transitions
% between \emph{execution states}. An execution state is a pair $T~|~P$
% where $T$ is a set of concurrent threads and $P$ is a set of
% FlowPools. Each thread executes a \emph{term} of the core language
% (typically a sequence of terms).
% State of a thread is represented as the (rest of)
% the term that it still has to execute; this means there is a
% one-to-one mapping between threads and terms.
% For example, the semantics of \verb|append| is defined by the
% following reduction rule (a complete summary of all the rules can be
% found in the appendix):
%
% \infrule[\textsc{Append1}]
% { t = p << v~;~t' \quad p = (vs, cbs, -1) \quad p' = (\set{v} \cup vs, cbs, -1)
% }
% { \reduce {t, T} {p, P} {t', T} {p', P}
% }
% \noindent
% Append simply adds the value $v$ to the pool $p$, yielding a modified
% pool $p'$. Note that this rule can only be applied if the pool $p$ is
% not sealed (the seal size is $-1$). The rule for $foreach$ modifies
% the set of callback functions in the pool:
%
% \infrule[\textsc{Foreach2}]
% { t = p~\texttt{foreach}~f~;~t' \quad p = (vs, cbs, n) \\
%   T' = \set{g(v)~|~g \in \set{f} \cup cbs, v \in vs} \quad p' = (vs, \set{f} \cup cbs, n)
% }
% { \reduce {t, T} {p, P} {t', T, T'} {p', P}
% }
% \noindent
% This rule only applies if $p$ is sealed at size $n$, meaning that
% no more elements will be appended later. Therefore, an
% invocation of the new callback $f$ is scheduled for each
% element $v$ in the pool. Each invocation creates a new thread in $T'$.
%
% Programs are built by first creating one or more FlowPools using
% \texttt{create}. Concurrent threads can then be started by (a)
% appending an element to a FlowPool, (b) sealing the FlowPool
% and (c) registering callback functions (\texttt{foreach}).
%
% \begin{definitiontwo}[Termination]
% A term $t$ terminates with result $P$ if its reduction ends in
% execution state $\set{t : t = \set{\epsilon}}~|~P$.
% \end{definitiontwo}
%
% \begin{definitiontwo}[Interleaving]
%   Consider the reduction of a term $t$: $T_1~|~P_1 \;\longrightarrow\;
%   T_2~|~P_2 \;\longrightarrow\; \ldots \;\longrightarrow\;
%   \set{t : t = \set{\epsilon}}~|~P_n$. An \emph{interleaving} is a reduction of $t$
%   starting in $T_1~|~P_1$ in which reduction rules are
%   applied in a different order.
% \end{definitiontwo}
%
% %\begin{definitiontwo}[Valid Interleaving]
% %An interleaving $S', c, S''$ of a reduction sequence $S$ is \emph{valid}
% %\emph{iff} for any reduction step $c$ using rule (\textsc{Create}), if
% %$c$ creates pool $p$, $p$ is not used in any reduction step in $S'$.
% %\end{definitiontwo}
%
% \begin{definitiontwo}[Determinism]
% The reduction of a term $t$ is \emph{deterministic} \emph{iff} either
% (a) $t$ does not terminate for any interleaving, or (b) $t$ always
% terminates with the same result for all interleavings.
% \end{definitiontwo}
%
% \begin{theoremtwo}[FlowPool Determinism]
% Reduction of terms $t$ is deterministic.
% \end{theoremtwo}


\section{Proof of Correctness}
\label{appendix-correctness}

% \setcounter{lemmatwo}{0}
% \setcounter{theoremtwo}{0}
% % \setcounter{cor}{0}
% \setcounter{definition}{0}

\begin{definitiontwo}[Data types]
A \textbf{Block} $b$ is an object which
contains an array $b.array$, which itself can contain elements, $e \in Elem$,
where \textbf{Elem} represents the type of $e$ and can be any countable set. A
given block $b$ additionally contains an index $b.index$ which represents an
index location in $b.array$, a unique index identifying the array
$b.blockIndex$, and $b.next$, a reference to a successor block $c$ where
$c.blockIndex = b.blockIndex + 1$. A \textbf{Terminal} $term$ is a sentinel
object, which contains an integer $term.sealed \in \{-1\} \cup \mathbb{N}_0$, and
$term.callbacks$, a set of functions $f \in Elem \Rightarrow Unit$.

We define the following functions:

\begin{align*}
following(b: Block) =
\begin{cases}
\emptyset & \text{if b.next = null,}
\\
b.next \cup following(b.next) & \text{otherwise}
\end{cases}
\end{align*}

\vspace{-1cm}
\begin{align*}
reachable(b: Block) = \{ b \} \cup following(b)
\end{align*}

\vspace{-1cm}
\begin{align*}
last(b: Block) = b' : b' \in reachable(b) \wedge b'.next = null
\end{align*}

\vspace{-1cm}
\begin{align*}
size(b: Block) = | \{ x : x \in b.array \wedge x \in Elem \} |
\end{align*}

Based on them we define the following relation:

\vspace{-0.7cm}
\begin{align*}
reachable(b, c) \Leftrightarrow c \in reachable(b)
\end{align*}
\end{definitiontwo}

\vspace{-1cm}
\begin{definitiontwo}[FlowPool]
A \textbf{FlowPool} $pool$ is an object that
has a reference $pool.start$, to the first block $b_0$ (with $b_0.blockIndex=0$),
as well as a reference $pool.current$.
We sometimes refer to these just as $start$ and $current$, respectively.

A \textbf{scheduled callback invocation} is a pair $(f, e)$ of a function
$f \in Elem => Unit$ and an element $e \in Elem$.
The programming construct that adds such a pair to the set of
$futures$ is \verb=future { f(e) }=.

The \textbf{FlowPool state} is defined as a pair of the directed graph of
objects transitively reachable from the reference $start$ and the set
of scheduled callback invocations called $futures$.

A \textbf{state changing} or \textbf{destructive} instruction is any
atomic write or CAS instruction that changes the FlowPool state.

We say that the FlowPool \textbf{has an element} $e$ at some time
$t_0$ if and only if the relation $hasElem(start, e)$ holds.

\vspace{-1cm}
\begin{align*}
hasElem(start, e) \Leftrightarrow \exists b \in reachable(start), e
\in b.array
\end{align*}

We say that the FlowPool \textbf{has a callback} $f$ at some time
$t_0$ if and only if the relation $hasCallback(start, f)$ holds.

\vspace{-1cm}
\begin{align*}
hasCallback(start, f) &\Leftrightarrow& \forall b = last(start), b.array
= x^P \cdot t \cdot y^N, x \in Elem, \\
& & t = Terminal(seal, callbacks), f \in callbacks
\end{align*}

We say that a callback $f$ in a FlowPool \textbf{will be called} for
the element $e$ at some time $t_0$ if and only if the relation
$willBeCalled(start, e, f)$ holds.

\begin{align*}
willBeCalled(start, e, f) \Leftrightarrow \exists t_1, \forall t >
t_1, (f, e) \in futures
\end{align*}

We say that the FlowPool is \textbf{sealed} at the size $s$ at some
$t_0$ if and only if the relation $sealedAt(start, s)$ holds.

\vspace{-1cm}
\begin{align*}
sealedAt(start, s) &\Leftrightarrow& s \neq -1 \wedge \forall b = last(start), b.array
= x^P \cdot t \cdot y^N, \\
& &x \in Elem, t = Terminal(s, callbacks)
\end{align*}

\textbf{FlowPool operations} are \verb=append=, \verb=foreach= and
\verb=seal=, and are defined by pseudocodes in Figure \ref{f-pseudo}.
\end{definitiontwo}


\begin{definitiontwo}[Invariants]
We define the following invariants for the \textbf{FlowPool}:
\begin{description}
\item[INV1] $start = b: Block, b \neq null, current \in reachable(start)$
\item[INV2] $\forall b \in reachable(start), b \not \in following(b)$
\item[INV3] $\forall b \in reachable(start), b \neq last(start) \Rightarrow size(b) = LASTELEMPOS \wedge b.array(BLOCKSIZE - 1) \in Terminal$
\item[INV4]
$\forall b = last(start), b.array = p \cdot c \cdot n$, where:

$p = X^P, c = c_1 \cdot c_2, n = null^N$

$x \in Elem, c_1 \in Terminal, c_2 \in \{null\} \cup Terminal$

$P + N + 2 = BLOCKSIZE$
\item[INV5] $\forall b \in reachable(start), b.index > 0 \Rightarrow b.array(b.index - 1) \in Elem$
\end{description}
\end{definitiontwo}


\begin{definitiontwo}[Validity]
A FlowPool state $\mathbb{S}$ is \textbf{valid} if and only if the invariants [INV1-5] hold for that state.
\end{definitiontwo}


\begin{definitiontwo}[Abstract pool]
An \textbf{abstract pool} $\mathbb{P}$ is a function from time $t$ to a tuple $(elems, callbacks, seal)$ such that:
\begin{description}
\item $seal \in \{ -1 \} \cup \mathbb{N}_0$
\item $callbacks \subset \{ (f: Elem => Unit, called) \}$
\item $called \subseteq elems \subseteq Elem$
\end{description}
We say that an abstract pool $\mathbb{P}$ \textbf{is in state}
$\mathbb{A} = (elems, callbacks, seal)$ at time $t$ if and only if $\mathbb{P}(t) = (elems, callbacks, seal)$.
\end{definitiontwo}


\begin{definitiontwo}[Abstract pool operations]
We say that an \textbf{abstract pool operation} $op$ that is applied to some
abstract pool $\mathbb{P}$ in abstract state $\mathbb{A}_0 = (elems_0, callbacks_0, seal_0)$
at some time $t$ \textbf{changes} the abstract state of the abstract
pool to $\mathbb{A} = (elems, callbacks, seal)$ if $\exists t_0,
\forall \tau, t_0 < \tau < t, \mathbb{P}(\tau) = \mathbb{A}_0$
and $\mathbb{P}(t) = \mathbb{A}$.
We denote this as $\mathbb{A} = op(\mathbb{A}_0)$.

Abstract pool operation $foreach(f)$ changes the abstract state at $t_0$ from $(elems, callbacks, seal)$
to $(elems, (f, \emptyset) \cup callbacks, seal)$. Furthermore:

\vspace{-1cm}
\begin{align*}
\exists t_1 \geq t_0, & & \forall t_2 > t_1, \mathbb{P}(t_2) = (elems_2,
callbacks_2, seal_2) \\
& & \wedge \forall (f, called_2) \in callbacks_2, elems \subseteq
called_2 \subseteq elems_2
\end{align*}

Abstract pool operation $append(e)$ changes the abstract state at $t_0$ from
$(elems, callbacks, seal)$ to $(\{e\} \cup elems, callbacks, seal)$. Furthermore:

\vspace{-1cm}
\begin{align*}
\exists t_1 \geq t_0, & & \forall t_2 > t_1, \mathbb{P}(t_2) = (elems_2,
callbacks_2, seal_2) \\
& & \wedge \forall (f, called_2) \in callbacks_2, (f, called) \in
callbacks \Rightarrow e \in called_2
\end{align*}

Abstract pool operation $seal(s)$ changes the abstract state of the
FlowPool at $t_0$ from $(elems, callbacks, seal)$ to $(elems,
callbacks, s)$, assuming that $seal \in \{-1\} \cup \{s\}$ and $s \in
\mathbb{N}_0$, and $|elems| \leq s$.
\end{definitiontwo}


\begin{definitiontwo}[Consistency]
A FlowPool state $\mathbb{S}$ is \textbf{consistent} with an abstract pool
$\mathbb{P} = (elems, callbacks, seal)$ at $t_0$ if and only if $\mathbb{S}$
is a valid state and:
\begin{description}
\item $\forall e \in Elem, hasElem(start, e) \Leftrightarrow e \in elems$
\item $\forall f \in Elem => Unit, hasCallback(start, f) \Leftrightarrow f \in callbacks$
\item $\forall f \in Elem => Unit, \forall e \in Elem, willBeCalled(start, e, f) \Leftrightarrow \exists t_1 \geq t_0, \forall t_2 > t_1, \mathbb{P}(t_2) = (elems_2, (f, called_2) \cup callbacks_2, seal_2), elems \subseteq called_2$
\item $\forall s \in \mathbb{N}_0, sealedAt(start, s) \Leftrightarrow s = seal$
\end{description}

A FlowPool operation $op$ is \textbf{consistent} with the corresponding
abstract state operation $op'$ if and only if $\mathbb{S'}=op(\mathbb{S})$ is consistent
with an abstract state $\mathbb{A'}=op'(\mathbb{A})$.

A \textbf{consistency change}
is a change from state $\mathbb{S}$ to state $\mathbb{S'}$ such that $\mathbb{S}$
is consistent with an abstract state $\mathbb{A}$ and $\mathbb{S'}$ is consistent
with an abstract set $\mathbb{A'}$, where $\mathbb{A} \neq \mathbb{A'}$.

%A FlowPool operation $op$ completing at some time $t_0$ is \textbf{consistent} with an abstract pool operation $op'$ if
%and only if $op$ changes the state of the FlowPool from $\mathbb{S}_1$ to $\mathbb{S}_2$, where $\mathbb{S}_1$
%and $\mathbb{S}_2$ are consistent with the abstract pool states $\mathbb{A}_1$ and $\mathbb{A}_2$, respectively,
%and $op'$ changes the state of the abstract pool from $\mathbb{A}_1$ to $\mathbb{A}_2$.
\end{definitiontwo}


\begin{proptwo}
Every valid state is consistent with some abstract pool.
\end{proptwo}

%
% \begin{theoremtwo}[Safety]
% FlowPool operation \verb=create= creates a new FlowPool consistent with the abstract pool
% $\mathbb{P} = (\emptyset, \emptyset, -1)$. FlowPool operations \verb=foreach=, \verb=append=
% and \verb=seal= are consistent with the abstract pool semantics.
% \end{theoremtwo}
%
%
% \begin{lemmatwo}[End of life]\label{lemma-end-of-life}
% For all blocks $b \in reachable(start)$, if value $v \in Elem$ is
% written to $b.array$ at some position $idx$ at some time $t_0$, then
% $\forall t > t_0, b.array(idx) = v$.
% \end{lemmatwo}
%
% \begin{prooftwo}
% The CAS in line \ref{cas_append} is the only CAS which writes an
% element.
% No other CAS has a value of type $Elem$ as the expected value.
% This means that once the CAS in line \ref{cas_append} writes a value
% of type $Elem$, no other write can change it.
% \end{prooftwo}
%
%
% \begin{cor}\label{cor-end-of-life}
% The end of life lemma implies that if all the values in $b.array$ are
% of type $Elem$ at $t_0$, then $\forall t > t_0$ there is no write to $b.array$.
% \end{cor}
%
%
% \begin{lemmatwo}[Valid hint]\label{lemma-valid-hint}
% For all blocks $b \in reachable(start)$, if $b.index > 0$ at some time $t_0$, then
% $b.array(b.index - 1) \in Elem$ at time $t_0$.
% \end{lemmatwo}
%
% \begin{prooftwo}
% Observe every write to $b.index$ -- they are all unconditional.
% However, at every such write occurring at some time $t_1$ that writes
% some value $idx$ we know that some previous value at $b.array$ entry $idx - 1$
% at some time $t_0 < t_1$ was of type $Elem$.
% Hence, from \ref{lemma-end-of-life} it follows that
% $\forall t \geq t_1, b.array(idx - 1) \in Elem$.
% \end{prooftwo}
%
%
% \begin{cor}[Compactness]\label{cor-compactness}
% For all blocks $b \in reachable(start)$, if for some $idx$
% $b.array(idx) \in Elem$ at time $t_0$ then $b.array(idx - 1) \in Elem$
% at time $t_0$. This follows
% directly from the \ref{lemma-end-of-life} and
% \ref{lemma-valid-hint}, and the fact that the CAS in line
% \ref{cas_append} only writes to array entries $idx$ for which it
% previously read the value from $b.index$.
% \end{cor}
%
%
% \begin{definitiontwo}[Transition]
% If for a function $f(t)$ there exist times $t_0$ and $t_1$ such that
% $\forall t, t_0 < t < t_1, f(t) = v_0$ and $f(t_1) = v_1$, then we say
% that the function $f$ goes through a \textbf{transition} at $t_1$. We denote this as:
%
% $f: v_0 \stackrel{t_1}{\rightarrow} v_1$
%
% Or, if we don't care about the exact time $t_1$, simply as:
%
% $f: v_0 \rightarrow v_1$
% \end{definitiontwo}
%
%
% \begin{definitiontwo}[Monotonicity]
% A function of time $f(t)$ is said to be \textbf{monotonic}, if every value in its string of transitions occurs only once.
% \end{definitiontwo}
%
%
% \begin{lemmatwo}[Freshness]\label{lemma-freshness}
% For all blocks $b \in reachable(start)$, and for all $x \in b.array$,
% function $x$ is monotonic.
% \end{lemmatwo}
%
% \begin{prooftwo}
% CAS instruction in line \ref{cas_append} writes a value of type
% $Elem$. No CAS instruction has a value of type $Elem$ as the expected value,
% so this write occurs only once.
%
% Trivial analysis of CAS instructions in lines \ref{cas_seal} and
% \ref{cas_callback}, shows that their expected values are of type
% $Terminal$. Their new values are always freshly allocated.
%
% The more difficult part is to show that CAS instruction in line
% \ref{cas_propagate} respects the statement of the lemma.
%
% Since the CAS instructions in lines \ref{cas_seal} and
% \ref{cas_callback} are preceeded by a read of $idx = b.index$,
% from \ref{lemma-valid-hint} it follows that $b.array(idx - 1)$
% contains a value of type $Elem$.
% These are also the only CAS instructions which replace a $Terminal$
% value with another $Terminal$ value. The new value is always unique, as
% shown above.
%
% So the only potential CAS to write a non-fresh value to $idx + 1$ is the CAS
% in line \ref{cas_propagate}.
%
% A successful CAS in line \ref{cas_propagate} overwrites a value $cb_0$ at $idx + 1$
% read in line \ref{read_next} at $t_0$ with a new value $cb_2$ at time $t_2$. Value $cb_2$ was
% read in line \ref{read_current} at $t_1$ from the entry $idx$. The
% string of transitions of values at $idx$ is composed of unique values
% at least since $t_1$ (by \ref{lemma-end-of-life}), since there is
% a value of type $Elem$ at the index $idx - 1$.
%
% The conclusion above ensures that the values read in line \ref{read_current}
% to be subsequently used as new values for the CAS in line \ref{cas_propagate}
% form a monotonic function $f(t) = b.array(idx) \text{ at } t$.
%
% Now assume that a thread T1 successfully overwrites $cb_0$
% via CAS in line \ref{cas_propagate} at $idx + 1$ at time $t_2$
% to a value $cb_2$ read from $idx$ at $t_1$, and that another thread T2
% is the \textbf{first} thread (since the FlowPool was created) to subsequently successfully
% complete the CAS in line \ref{cas_propagate} at $idx + 1$ at time
% $t_{prev2} > t_2$ with some value $cb_{prev2}$ which was at $idx + 1$ at some time
% $t < t_0$.
%
% That would mean that $b.array(idx + 1)$ does not change during $\langle t_0, t_2 \rangle$,
% since T2 was the first thread the write a non-fresh value to $idx + 1$, and any
% other write would cause the CAS in line \ref{cas_propagate} by T1 to fail.
% %That means that $t_0 > t_{prev0}$, otherwise the CAS in line \ref{cas_propagate}
% %by T2 would have failed.
%
% Also, that would mean that the thread T2 read the value
% $cb_{prev2}$ in line \ref{read_current} at some time $t_{prev1} < t_1$
% and successfully completed the CAS at time $t_{prev2} > t_2$. If the
% CAS was successful, then the read in line \ref{read_next} by T2
% occured at $t_{prev0} < t_{prev1} < t_1$. Since we assumed that T2 is the
% first thread to write a value $cb_{prev2}$ to $idx + 1$ at time $t_{prev2}$
% which was previously in $idx + 1$ at some time $t < t_0$, then the CAS
% in line \ref{cas_propagate} at time $t_{prev2}$ could not have succeeded,
% since its expected value is $cb_{prev0}$ read at some time $t_{prev0}$, and
% we know that the value at $idx + 1$ was changed at least once in $\langle t_{prev0}, t_{prev2} \rangle$
% because of the write of a fresh value by thread T1 at $t_2 \in \langle t_{prev0}, t_{prev2} \rangle$.
% This value is known to be fresh because $b.array(idx)$ is a monotonic
% function at least since $t_{prev1}$, and the read of the new value
% written by T1 occurred at $t_1 > t_{prev1}$.
% We also know that there is no other thread T3 to write the value
%  $cb_{prev0}$ during $\langle t_{prev0}, t_{prev2} \rangle$
% back to $idx + 1$, since we assumed that T2 is the first to write
% a non-fresh value at that position.
%
% Hence, a contradiction shows that there is no thread T2 which is the \textbf{first}
% to write a non-fresh value via CAS in line \ref{cas_propagate} at $idx + 1$
% for any $idx$, so there is no thread that writes a non-fresh value at all.
% \end{prooftwo}
%
%
% \begin{lemmatwo}[Lifecycle]\label{lemma-lifecycle}
% For all blocks $b \in reachable(start)$, and for all $x \in b.array$, function $x$ goes through and only through the prefix of the following transitions:
%
% $null \rightarrow cb_1 \rightarrow \dots \rightarrow cb_n \rightarrow elem$, where:
%
% $cb_i \in Terminal, i \neq j \Rightarrow cb_i \neq cb_j, elem \in Elem$
% \end{lemmatwo}
%
% \begin{prooftwo}
% First of all, it is obvious from the code that each block that becomes
% an element of $reachable(start)$ at some time $t_0$ has the value of
% all $x \in b.array$ set to $null$.
%
% Next, we inspect all the CAS instructions that operate on entries of
% $b.array$.
%
% The CAS in line \ref{cas_append} has a value $curo \in Terminal$ as
% an expected value and writes an $elem \in Elem$.
% This means that the only transition that this CAS
% can cause is of type $cb_i \in Terminal \rightarrow elem \in Elem$.
%
% We will now prove that the CAS in line \ref{cas_propagate} at time $t_2$ is successful if and
% only if the entry at $idx + 1$ is $null$ or $nexto \in
% Terminal$.
% We know that the entry at $idx + 1$ does not change $\forall t, t_0 < t < t_2$,
% where $t_0$ is the read in line \ref{read_next},
% because of \ref{lemma-freshness} and the fact that CAS in line \ref{cas_propagate} is assumed to be successful.
% We know that during the read in line \ref{read_current} at time $t_1$,
% such that $t_0 < t_1 < t_2$, the entry at $idx$ was $curo \in
% Terminal$, by trivial analysis of the \verb=check= procedure.
% It follows from corollary \ref{cor-compactness} that the array entry $idx
% + 1$ is not of type $Elem$ at time $t_1$, otherwise array entry $idx$
% would have to be of type $Elem$.
% Finally, we know that the entry at $idx + 1$ has the same value during
% the interval $\langle t_1, t_2 \rangle$, so its value is not $Elem$ at $t_2$.
%
% The above reasoning shows that the CAS in line \ref{cas_propagate}
% always overwrites a one value of type $Terminal$ (or $null$) with
% another value of type $Terminal$.
% We have shown in \ref{lemma-freshness} that it never
% overwrites the value $cb_0$ with a value $cb_2$ that was at
% $b.array(idx)$ at an earlier time.
%
% Finally, note that the statement for CAS instructions in lines \ref{cas_seal} and
% \ref{cas_callback} also follows directly from the proof for \ref{lemma-freshness}.
% \end{prooftwo}
%
%
% \begin{lemmatwo}[Subsequence]\label{lemma-subsequence}
% Assume that for some block $b \in reachable(start)$ the transitions of
% $b.array(idx)$ are:
%
% \begin{equation*}
% b.array(idx): null \rightarrow cb_1 \rightarrow \cdots \rightarrow
% cb_n \stackrel{t_0}{\rightarrow} elem: Elem
% \end{equation*}
%
% Assume that the transitions of $b.array(idx + 1)$ up to time $t_0$ are:
%
% \begin{equation*}
% b.array(idx + 1): null \rightarrow cb_1' \rightarrow \cdots
% \rightarrow cb_m'
% \end{equation*}
%
% The string of transitions $null \rightarrow cb_1' \rightarrow \cdots
% \rightarrow cb_m'$ is a subsequence of $null \rightarrow cb_1
% \rightarrow \cdots \rightarrow cb_n$.
% \end{lemmatwo}
%
% \begin{prooftwo}
% Note that all the values written to $idx + 1$ before $t_0$ by CAS in line \ref{cas_propagate} were
% previously read from $idx$ in line \ref{read_current}.
% This means that the set of values occurring in $b.array(idx + 1)$
% before $t_0$ is a subset of the set of values in $b.array(idx)$.
% We have to prove that it is actually a subsequence.
%
% Assume that there exist two values $cb_1$ and $cb_2$ read by threads T1 and T2
% in line \ref{read_current} at times $t_1$ and $t_2 > t_1$, respectively.
% Assume that these values are written to $idx + 1$ by threads T1 and T2
% in line \ref{cas_propagate} in the opposite order, that is at times
% $t_{cas1}$ and $t_{cas2} < t_{cas1}$, respectively.
% That would mean that the CAS by thread T1 would have to fail, since its expected
% value $cb_0$ has changed between the time it was read in line \ref{read_next} and
% the $t_{cas1}$ at least once to a different value, and it could not have been
% changed back to $cb_0$ as we know from the \ref{lemma-freshness}.
%
% Notice that we have actually prooved a stronger result above.
% We have also shown that the string of values
% written at $idx + 1$ by CAS in line \ref{cas_propagate} successfully is a subsequence
% of \textbf{all} the transitions of values at $idx$ (not just until $t_0$).
% \end{prooftwo}
%
%
% \begin{lemmatwo}[Valid writes]\label{lemma-valid}
% Given a FlowPool in a valid state, all writes in all operations produce a FlowPool in a valid state.
% \end{lemmatwo}
%
% \begin{prooftwo}
% A new FlowPool is trivially in a valid state.
%
% Otherwise, assume that the FlowPool is in a valid state
% $\mathbb{S}$.
% In the rest of the proof, whenever some invariant is trivially
% unaffected by a write, we omit mentioning it.
% We start by noting that we already prooved the claim
% for atomic writes in lines \ref{write_append}, \ref{write_advance} and
% \ref{write_seal} (which only affect [INV5]) in \ref{lemma-valid-hint}.
% We proceed by analyzing each atomic CAS instruction.
%
% CAS in line \ref{cas_expand} at time $t_1$ maintains the invariant
% [INV1].
% This is because its expected value is always
% $null$, which ensures that the lifecycle of $b.next$ is $null
% \rightarrow b': Block$, meaning that the function $reachable(start)$
% returns a monotonically growing set.
% So if $current \in reachable(start)$ at $t_0$, then this also holds at
% $t_1 > t_0$.
% It also maintains [INV2] because the new value $nb$ is always fresh,
% so $\forall b, b \not \in following(b)$.
% Finally, it maintains [INV3] because it is preceeded with a bounds
% check and we know from corollary \ref{cor-compactness} and the
% \ref{lemma-end-of-life} that all the values in $b.array(idx),
% idx < LASTELEMPOS$ must be of type $Elem$.
%
% CAS in line \ref{cas_block} at time $t_1$ maintains the
% invariant [INV1], since the new value for the $current \neq null$ was read from
% $b.next$ at $t_0 < t_1$ when the invariant was assumed to hold, and
% it is still there a $t_1$, as shown before.
%
% For CAS instructions in lines \ref{cas_append}, \ref{cas_callback} and
% \ref{cas_seal} that write to index $idx$ we know from
% \ref{lemma-valid-hint} that the value at $idx - 1$ is of type $Elem$.
% This immediately shows that CAS instructions in lines
% \ref{cas_callback} and \ref{cas_seal} maintain [INV3] and [INV4].
%
% For CAS in line \ref{cas_append} we additionally know that it must
% have been preceeded by a successful CAS in line \ref{cas_propagate}
% which previously wrote a $Terminal$ value to $idx + 1$. From
% \ref{lemma-lifecycle} we know that $idx + 1$ is still $Terminal$ when
% the CAS in line \ref{cas_append} occurs, hence [INV4] is kept.
%
% Finally, CAS in line \ref{cas_propagate} succeeds only if the value at
% $idx + 1$ is of type $Terminal$, as shown before in
% \ref{lemma-lifecycle}.
% By the same lemma, the value at $idx$ is either
% $Terminal$ or $Elem$ at that point, since $idx - 1$ is known to be
% $Elem$ by \ref{lemma-valid-hint}.
% This means that [INV4] is kept.
% \end{prooftwo}
%
%
% \begin{lemmatwo}[Housekeeping]\label{lemma-housekeeping}
% Given a FlowPool in state $\mathbb{S}$ consistent with some abstract
% pool state $\mathbb{A}$, CAS instructions in lines \ref{cas_propagate}, \ref{cas_expand} and
% \ref{cas_block} do not change the abstract pool state $\mathbb{A}$.
% \end{lemmatwo}
%
% \begin{prooftwo}
% Since none of the relations $hasElem$, $hasCallback$, $willBeCalled$ and $sealedAt$
% are defined by the value of $current$ CAS in line \ref{cas_block}
% does not change them, hence it does not change the abstract pool
% state.
%
% No CAS changes the set of scheduled futures, nor is
% succeeded by a \verb=future= construct so it does not affect
% the $willBeCalled$ relation.
%
% It is easy to see that the CAS in line \ref{cas_expand} does not remove any elements, nor make
% any additional elements reachable, since the new block $nb$ which
% becomes reachable does not contain any elements at that time.
% Hence the $hasElem$ relation is not affected.
% It does change the value $last(start)$ to $nb$, but since $nb.array =
% t \cdot null^{BLOCKSIZE - 1}$, where $t \in Terminal$ was previously
% the last non-null element in $b.array$, it does changes neither the
% $sealedAt$ nor the $hasCallback$ relation.
%
% The CAS in line \ref{cas_propagate} does not make some new element reachable,
% hence the $hasElem$ relation is preserved.
%
% Note now that this CAS does not change the relations $hasCallback$
% and $sealedAt$ as long as there is a value of type $Terminal$ at the
% preceeding entry $idx$.
% We claim that if the CAS succeeds at $t_2$, then
% either the value at $idx$ is of type $Terminal$ (trivially) or the CAS
% did not change the value at $idx + 1$.
% In other words, if the value at $idx$ at time $t_2$ is of type $Elem$,
% then the write by CAS in line \ref{cas_propagate} does not change
% the value at $idx + 1$ at $t_2$.
% This was, in fact, already shown in the proof of \ref{lemma-subsequence}.
%
% The argument above proves directly that relations $hasCallback$
% and $sealedAt$ are not changed by the CAS in line \ref{cas_propagate}.
% \end{prooftwo}
%
%
% \begin{lemmatwo}[Append correctness]\label{lemma-append}
% Given a FlowPool in state $\mathbb{S}$ consistent with some abstract pool state $\mathbb{A}$,
% a successful CAS in line \ref{cas_append} at some time $t_0$ changes the state of the FlowPool
% to $\mathbb{S}_0$ consistent with an abstract pool state $\mathbb{A}_0$, such that:
%
% $\mathbb{A} = (elems, callbacks, seal)$
%
% $\mathbb{A}_0 = (\{elem\} \cup elems, callbacks, seal)$
%
% Furthermore, given a fair scheduler, there exists a time $t_1 > t_0$ at which the FlowPool
% is consistent with an abstract pool in state $\mathbb{A}_1$, such that:
%
% $\mathbb{A}_1 = (elems_1, callbacks_1, seal_1)$, where:
%
% $\forall (f, called_1) \in callbacks_1, (f, called) \in callbacks \Rightarrow elem \in called_1$
% \end{lemmatwo}
%
% \begin{prooftwo}
% Assume that the CAS in line \ref{cas_append} succeeds at some time
% $t_3$, the CAS in line \ref{cas_propagate} succeeds at some time $t_2 <
% t_3$, the read in line \ref{read_current} occurs at some time $t_1 <
% t_2$ and the read in line \ref{read_current} occurs at some time $t_0
% < t_1$.
%
% It is easy to see from the invariants, $check$ procedure and the
% corollary \ref{cor-end-of-life} that the CAS in line \ref{cas_append} can only
% occur if $b = last(start)$.
%
% We claim that for the block $b \in reachable(start)$ such that $b = last(b)$ the
% following holds at $t_2$:
%
% $b.array = elem^N \cdot cb_1 \cdot cb_2 \cdot null^{BLOCKSIZE - N - 2}$
%
% where $cb_1 = cb_2$, since there was no write to $idx$ after $cb_1$, otherwise the
% CAS in line \ref{cas_append} at $t_3$ would not have been successful
% (by lemma \ref{lemma-freshness}).
%
% Furthermore, $cb_1 = cb_2$ at $t_3$, as shown in the
% \ref{lemma-subsequence}. Due to the same lemma, the entries of
% $b.array$ stay the same until $t_3$, otherwise the CAS in line
% \ref{cas_append} would not have been successful.
% After the successful CAS at $t_3$, we have:
%
% $b.array = elem^N \cdot e \cdot cb_1 \cdot null^{BLOCKSIZE - N - 2}$
%
% where $e: Elem$ is the newly appended element-- at $t_3$ the relation
% $hasElem(start, e)$ holds, and $sealedAt(start, s)$ and $hasCallback(start,
% f)$ did not change between $t_2$ and $t_3$.
%
% It remains to be shown that $willBeCalled(start, e, f)$ holds at $t_3$.
% Given a fair scheduler, within a finite number of steps the
% future store will contain a request for an asynchronous computation
% that invokes $f$ on $e$. The fair scheduler ensures that the future is
% scheduled within a finite number of steps.
% \end{prooftwo}
%
%
% \begin{lemmatwo}[Foreach correctness]\label{lemma-foreach}
% Given a FlowPool in state $\mathbb{S}$ consistent with some abstract pool state $\mathbb{A}$,
% a successful CAS in line \ref{cas_callback} at some time $t_0$ changes the state of the FlowPool
% to $\mathbb{S}_0$ consistent with an abstract pool state $\mathbb{A}_0$, such that:
%
% $\mathbb{A} = (elems, callbacks, seal)$
%
% $\mathbb{A}_0 = (elems, (f, \emptyset) \cup callbacks, seal)$
%
% Furthermore, given a fair scheduler, there exists a time $t_1 \geq t_0$ at which the FlowPool
% is consistent with an abstract pool in state $\mathbb{A}_1$, such that:
%
% $\mathbb{A}_1 = (elems_1, callbacks_1, seal_1)$, where:
%
% $elems \subseteq elems_1$
%
% $\forall (f, called_1) \in callbacks_1, elems \subseteq called_1$
% \end{lemmatwo}
%
% \begin{prooftwo}
% From \ref{lemma-freshness} and the assumption that the CAS is
% successful we know that the value at $b.array(idx)$ has not changed
% between the read in line \ref{read_callback} and the CAS in line
% \ref{cas_callback}.
% From \ref{lemma-valid-hint} we know that the value at $idx - 1$
% was of type $Elem$ since $b.index$ was read.
% This means that neither $hasElem(start, e)$ nor $sealedAt$ have changed after the CAS.
% Since after the CAS there is a $Terminal$ with an additional function $f$ at $idx$,
% the $hasCallback(start, f)$ holds after the CAS.
% Finally, the $willBeCalled(start, e, f)$ holds for all elements $e$
% for which the $hasElem(e)$ holds, since the CAS has been preceeded by
% a call $f(e)$ in line \ref{call_callback} for each element. The
% \ref{lemma-end-of-life} ensures that for each element $f$ was called
% for stays in the pool indefinitely (i.e. is not removed).
%
% Trivially, the time $t_1$ from the statement of the lemma is such that $t_1 = t_0$.
% \end{prooftwo}
%
%
% \begin{lemmatwo}[Seal correctness]\label{lemma-seal}
% Given a FlowPool in state $\mathbb{S}$ consistent with some abstract pool state $\mathbb{A}$,
% a successful CAS in line \ref{cas_seal} at some time $t_0$ changes the state of the FlowPool
% to $\mathbb{S}_0$ consistent with an abstract pool state $\mathbb{A}_0$, such that:
%
% $\mathbb{A} = (elems, callbacks, seal)$, where $seal \in \{ -1 \} \cup
% \{ s \}$
%
% $\mathbb{A}_0 = (elems, callbacks, \{ s \})$
% \end{lemmatwo}
%
% \begin{prooftwo}
% Similar to the proof of \ref{lemma-foreach}.
% \end{prooftwo}
%
%
% \begin{definitiontwo}[Obstruction-freedom]
% Given a FlowPool in a valid state, an operation $op$ is
% \textbf{obstruction-free} if and only if a thread T executing the
% operation $op$ completes within a finite number of steps given that
% no other thread was executing the operation $op$ since T started executing it.
%
% We say that thread T executes the operation $op$ \textbf{in isolation}.
% \end{definitiontwo}
%
%
% \begin{lemmatwo}[Obstruction-free operations]\label{lemma-obstruction-free}
% All operations on FlowPools are obstruction-free.
% \end{lemmatwo}
%
% \begin{prooftwo}
% By trivial sequential code analysis supported by the fact that the
% invariants (especially [INV2]) hold in a valid state.
% \end{prooftwo}
%
%
% \begin{prooftwo}[Safety]
% From \ref{lemma-housekeeping}, \ref{lemma-append}, \ref{lemma-foreach} and
% \ref{lemma-seal} directly, along with the fact that all operations
% executing in isolation complete after a finite number of steps by \ref{lemma-obstruction-free}.
% \end{prooftwo}
%
%
% \begin{definitiontwo}[Linearizability]
% We say that an operation $op$ is linearizable if every thread
% observers that it completes at some time $t_0$ after it was invoked
% and before it finished executing.
% \end{definitiontwo}
%
%
% \begin{theoremtwo}[Linearizable operations]
% FlowPool operations \verb=append= and \verb=seal= are linearizable.
% \end{theoremtwo}
%
% \begin{prooftwo}[Linearizable operations]
% This follows directly from statements about CAS instructions in \ref{lemma-housekeeping},
% \ref{lemma-append} and \ref{lemma-seal}, along with the fact that a
% CAS instruction itself is linearizable.
% \end{prooftwo}
%
% Note that \verb=foreach= starts by executing an asynchronous
% computation and then returns the control to the caller. This means
% that the linearization point may happen outside the execution interval
% of that procedure -- so, \verb=foreach= is not linearizable.


% \textbf{Definition 2} (FlowPool). typically pointing to some
% subsequent block $b_n$ where $b_n=b_0$ or where $b_n$ is reachable from $b_0$
% following $next$ references. Initially, $pool.current = pool.start$. The pool
% \textbf{state} $\mathbb{S}$ is defined as the sequence of blocks reachable
% from $pool.start$ by following $next$ references within blocks.
% A \textbf{state changing} instruction is any atomic write or CAS instruction
% that changes an object that can be accessed from $pool.start$.

% \textbf{Definition 3} (Invariants).

% \textbf{INV1} let $b: Block$ such that $reachable(start,b)\wedge b.next=null$.
% $\exists i$ such that $b.array(i) = Terminal \wedge \forall~i<j \leq LASTELEMPOS$,
% $b.array(j) = null$

% \textbf{Definition 4} (Abstract state). An \textbf{abstract state} $\mathbb{A}$
% is a tuple $(elems,sealed,callbacks)$ such that
% $\mathbb{A} \in \{(elems,sealed,callbacks)~|~elems \subset Elem,~sealed \in \{-1\} \cup \mathbb{N}_0,~callbacks\subset Elem \Rightarrow Unit\}$
% Abstract state operations on some abstract state $\mathbb{A}$ are $append(\mathbb{A},e) = \mathbb{A'}$
% where $\mathbb{A'} = (elems \cup \{e\}, sealed, callbacks)$ if $\mathbb{A}=(elems, sealed, callbacks)$,
% $seal(\mathbb{A},sealSize) = \mathbb{A''}$ where $\mathbb{A''} = (elems, sealSize, callbacks)~:~sealSize \in \mathbb{N}_0$
% if $\mathbb{A}=(elems, sealed, callbacks)$ and $sealed=-1$, the unsealed state, or
% $sealed=sealSize$ already, and
% $doForAll(\mathbb{A},fun)=\mathbb{A'''}$ where $\mathbb{A'''}=(elems, sealed, callbacks\cup \{fun\})$.

% \textbf{Definition 5} (Consistency). A FlowPool state $\mathbb{S}$ of $pool$
% with starting block $pool.start$ is consistent with an abstract state
% $\mathbb{A}=(elems,sealed)$ iff some element $e \in elems \Leftrightarrow \exists b,i~:~reachable(pool.start,b)~\wedge~b.array(i)=e,$
% and $\exists c,j~:~c.array(j) \in Terminal~\wedge~c.array(j).sealed=sealed~\wedge~reachable(pool.start, c)$.

\begin{definitiontwo}[Lock-freedom]\label{def-lock-freedom}
In a scenario where some finite number of threads are executing a concurrent
operation, that concurrent operation is \textit{lock-free} if and only if that
concurrent operation is completed after a finite number of steps by some
thread.
\end{definitiontwo}


\begin{theoremtwo}[Lock-freedom]\label{theorem-lock-freedom}
FlowPool operations \verb=append=, \verb=seal=, and \verb=foreach= are lock-free.

We begin by first proving that there are a finite number of execution steps
before a consistency change occurs.

By \ref{lemma-append}, after invoking \verb=append=, a consistency
change occurs after a finite number of steps. Likewise, by
\ref{lemma-finite-steps-consistency-change}, after invoking \verb=seal=, a consistency
change occurs after a finite number of steps. And finally, by
\ref{lemma-foreach-cons},
after invoking \verb=foreach=, a consistency change likewise
occurs after a finite number of steps.

By \ref{lemma-operation-completes}, this means a concurrent operation
\verb=append=, \verb=seal=, or \verb=foreach= will successfully complete.
Therefore, by \ref{def-lock-freedom},  these operations are lock-free.

\end{theoremtwo}

% CASes that fail by being completed by other CASes signify progress.

\noindent \textbf{Note.} For the sake of clarity in this section of the
correctness proof, we assign the following aliases to the following CAS and
WRITE instructions:

\begin{itemize}
\setlength{\itemindent}{-1em}
\item $CAS_{append-out}$ corresponds to the outer CAS in \verb=append=, on line \ref{cas_propagate}.
\item $CAS_{append-inn}$ corresponds to the inner CAS in \verb=append=, on line \ref{cas_append}.
\item $CAS_{expand-nxt}$ corresponds to the CAS on $next$ in \verb=expand=, line \ref{cas_expand}.
\item $CAS_{expand-curr}$ corresponds to the CAS on $current$ in \verb=expand=, line \ref{cas_block}.
\item $CAS_{seal}$ corresponds to the CAS on the $Terminal$ in \verb=tryWriteSeal=, line \ref{cas_seal}.
\item $CAS_{foreach}$ corresponds to the CAS on the $Terminal$ in \verb=asyncFor=, line \ref{cas_callback}.
\item $WRITE_{app}$ corresponds to the WRITE on the new $index$ in \verb=append=, line \ref{write_append}.
\item $WRITE_{adv}$ corresponds to the WRITE on the new $index$ in \verb=advance=, line \ref{write_advance}.
\item $WRITE_{seal}$ corresponds to the WRITE on the new $index$ in \verb=seal=, line \ref{write_seal}.
\end{itemize}

%==============================
% LEMMA 1
%==============================

\begin{lemmatwo}\label{lemma-non-consistency-cas} After invoking an operation
$op$, if non-consistency changing CAS operations $CAS_{append-out}$,
$CAS_{expand-nxt}$, or $CAS_{expand-curr}$, in the pseudocode fail, they must have
already been successfully completed by another thread since $op$ began.
\end{lemmatwo}

\begin{prooftwo} Trivial inspection of the pseudocode reveals that since $CAS_{append-out}$
makes up a check that precedes $CAS_{append-inn}$, and since
$CAS_{append-inn}$ is the only operation besides $CAS_{append-out}$ which can
change the expected value of $CAS_{append-out}$, in the case of a failure of
$CAS_{append-out}$, $CAS_{append-inn}$ (and thus $CAS_{append-out}$) must have
already successfully completed or $CAS_{append-out}$ must have already
successfully completed by a different thread since $op$ began executing.

Likewise, by trivial inspection $CAS_{expand-nxt}$ is the only CAS which can
update the $b.next$ reference, therefore in the case of a failure, some other
thread must have already successfully completed $CAS_{expand-nxt}$ since the
beginning of $op$.

Like above, $CAS_{expand-curr}$ is the only CAS which can change the $current$
reference, therefore in the case of a failure, some other thread must have
already successfully completed $CAS_{expand-curr}$ since $op$ began.
\qed
\end{prooftwo}

%==============================
% Lemma \ref{lemma-expand} (EXPAND)
%==============================

\begin{lemmatwo}[Expand]\label{lemma-expand}
Invoking the $expand$ operation will execute a non- consistency changing
instruction after a finite number of steps. Moreover, it is guaranteed that
the $current$ reference is updated to point to a subsequent block after a
finite number of steps. Finally, $expand$ will return after a finite number of
steps
% Furthermore, given a total number of blocks $numBlocks$ reachable in a
% FlowPool $pool$ before invoking $expand$ through \verb=append=, the number of
% blocks $numBlocks'$ after some finite number of steps is guaranteed to satisfy
% $numBlocks'>numBlocks$
\end{lemmatwo}

\begin{prooftwo}

From inspection of the pseudocode, it is clear that the only point at which
$expand(b)$ can be invoked is under the condition that for some block $b$,
$b.index > LASTELEMPOS$, where $LASTELEMPOS$ is the maximum size set aside for
elements of type $Elem$ in any block. Given this, we will proceed  by showing
that a new block will be created with all related references  $b.next$ and
$current$ correctly set.

There are two conditions under which a non-consistency changing CAS
instruction will be carried out.

\begin{itemize}  \item \textbf{Case 1:} if $b.next=null$, a new block $nb$
will be created and $CAS_{expand-nxt}$ will be executed. From
\ref{lemma-non-consistency-cas},  we know that $CAS_{expand-nxt}$
must complete successfully on some thread. Afterwards recursively calling
$expand$ on the original block $b$. \item \textbf{Case 2:} if $b.next \neq
null$, $CAS_{expand-curr}$ will be executed. \ref{lemma-non-consistency-cas}
guarantees that $CAS_{expand-curr}$ will update $current$ to refer to $b.next$,  which we
will show can only be a new block. Likewise, \ref{lemma-non-consistency-cas}
has shown that  $CAS_{expand-nxt}$ is the only state changing instruction that can
initiate a state change  at location $b.next$, therefore, since $CAS_{expand-nxt}$ takes
place within Case 1, Case 2 can only be reachable after Case 1 has been
executed successfully. Given  that Case 1 always creates a new block,
therefore, $b.next$ in this case, must  always refer to a new block.
\end{itemize}

Therefore, since from \ref{lemma-non-consistency-cas} we know that both
$CAS_{expand-nxt}$ and $CAS_{expand-curr}$ can only fail if already completed
guaranteeing their finite completion, and since $CAS_{expand-nxt}$ and
$CAS_{expand-curr}$ are the only state changing operations invoked through
$expand$, the $expand$ operation must complete in a finite number of steps.

Finally, since we saw in Case 2 that a new block is always created and related
references are always correctly set, that is both $b.next $ and $current$ are
correctly updated to refer to the new block, it follows that $numBlocks$
strictly increases after some finite number of steps.
\qed
\end{prooftwo}


%==============================
% Lemma \ref{lemma-cas2} (CAS2)
%==============================

\begin{lemmatwo}[$CAS_{append-inn}$]\label{lemma-cas2} After invoking \verb=append(elem)=, if
$CAS_{append-inn}$ fails, then some thread has successfully completed
$CAS_{append-inn}$ or $CAS_{seal}$ (or likewise, $CAS_{foreach}$) after some
finite number of steps.
\end{lemmatwo}

\begin{prooftwo}
First, we show that a thread attempting to complete $CAS_{append-inn}$ can't fail due to a
different thread completing $CAS_{append-out}$ so long as \verb=seal= has not been invoked
after completing the read of $currobj$. We address this exception later on.

Since after $check$, the only condition under which $CAS_{append-out}$, and by
extension, $CAS_{append-inn}$ can be executed is the situation where the
current object $currobj$ with index location $idx$ is the $Terminal$ object,
it follows that $CAS_{append-out}$ can only ever serve to duplicate this
$Terminal$ object at location $idx+1$, leaving at most two $Terminal$s in
block refered to by $current$ momentarily until $CAS_{append-inn}$ can be
executed. By \ref{lemma-non-consistency-cas}, since $CAS_{append-out}$ is a non-consistency changing
instruction, it follows that any thread holding any element $elem'$ can
execute this instruction without changing the expected value of $currobj$ in
$CAS_{append-inn}$, as no new object is ever created and placed in location
$idx$. Therefore, $CAS_{append-inn}$ cannot fail due to $CAS_{append-out}$, so
long as \verb=seal= has not been invoked by some other thread after the read
of $currobj$.

This leaves only two scenarios in which consistency changing
$CAS_{append-inn}$ can fail:

\begin{itemize}
\item \textbf{Case 1:} Another thread has already completed $CAS_{append-inn}$ with a
different element $elem'$.
\item \textbf{Case 2:} Another thread completes an invocation to the \verb=seal=
operation after the current thread completes the read of $currobj$. In this
case, $CAS_{append-inn}$ can fail because $CAS_{seal}$ (or, likewise $CAS_{foreach}$)
might have completed before, in which case, it inserts a new $Terminal$ object $term$
into location $idx$ (in the case of a \verb=seal= invocation,
$term.sealed\in\mathbb{N}_0$, or in the case of a \verb=foreach= invocation,
$term.callbacks\in\{Elem \Rightarrow Unit\}$).
\end{itemize}

We omit the proof and detailed discussion of $CAS_{foreach}$ because it can be proven
using the same steps as were taken for $CAS_{seal}$.
\qed
\end{prooftwo}

%==============================
% Lemma \ref{lemma-finite-steps-state-change} (FINITE # STEPS BEFORE STATE CHANGE)
%==============================

\begin{lemmatwo}[Finite Steps Before State Change]\label{lemma-finite-steps-state-change}
All operations with the exception of \verb=append=, \verb=seal=, and
\verb=foreach= execute only a finite number of steps between each state
changing instruction.
\end{lemmatwo}

\begin{prooftwo} The \verb=advance=, \verb=check=, \verb=totalElems=,
\verb=invokeCallbacks=, and \verb=tryWriteSeal= operations have a finite
number of execution steps, as they contain no recursive calls, loops, or other
possibility to restart.

While the \verb=expand= operation contains a recursive call following a CAS
instruction, it was shown in \ref{lemma-expand} that an invocation of
\verb=expand= is guaranteed to execute a state changing instruction after a
finite number of steps.

\qed
\end{prooftwo}

%==============================
% Lemma \ref{lemma-append} (APPEND: FINITE # STEPS BEFORE CONSISTENCY CHANGE)
%==============================

\begin{lemmatwo}[Append]\label{lemma-append}
After invoking \verb=append(elem)=, a consistency changing instruction will be
completed after a finite number of steps.
\end{lemmatwo}

\begin{prooftwo}
The \verb=append= operation can be restarted in three cases. We show that in
each case, it's guaranteed to either complete in a finite number of steps,  or
leads to a state changing instruction:

\begin{itemize}

\item \textbf{Case 1:} The call to \verb=check=, a finite operation by
\ref{lemma-finite-steps-state-change}, returns $false$,  causing a call to
\verb=advance=, also a finite operation by
\ref{lemma-finite-steps-state-change}, followed by a recursive call to
\verb=append= with the same element $elem$ which in turn once again calls
\verb=check=.

We show that after a finite number of steps, the \verb=check= will evaluate to
$true$, or some other thread will have completed a consistency changing
operation since the initial invocation of \verb=append=. In the case where
\verb=check= evaluates to $true$, \ref{lemma-cas2} applies, as it
guarantees that a consistency changing CAS is completed after a finite number
of steps.

When the call to the finite operation \verb=check= returns $false$, if the
subsequent \verb=advance= finds that a $Terminal$ object is at the current
block index $idx$, then the next invocation of \verb=append= will evaluate
\verb=check= to $true$. Otherwise, it must be the case that another thread has
moved the Terminal to a subsequent index since the initial invocation of
append, which is only possible using a consistency changing instruction.

Finally, if \verb=advance= finds that the element at $idx$ is an
$Elem$,
%% by Lemma 9,  TODO which lemma?
$b.index$ will be incremented after a finite number of steps. By
$INV1$, this can only happen a finite number of times until a $Terminal$ is
found. In the case that \verb=expand= is meanwhile invoked through
\verb=advance=, by \ref{lemma-expand} it's guaranteed to complete state
changing instructions $CAS_{expand-nxt}$ or $CAS_{expand-curr}$ in a finite
number of steps. Otherwise, some other thread has moved the $Terminal$ to a
subsequent index. However, this latter case is only possible by successfully
completing $CAS_{append-inn}$, a consistency changing instruction, after the
initial invocation of append.

\item \textbf{Case 2:} $CAS_{append-out}$ fails, which we know from
\ref{lemma-non-consistency-cas}means that it must've already been completed by
another thread, guaranteeing that $CAS_{append-inn}$ will be attempted. If
$CAS_{append-inn}$ fails,
%%by Lemma 3, TODO which lemma?
after a finite number of steps, a
consistency changing instruction will be completed. If $CAS_{append-inn}$
succeeds, as a consistency changing instruction, consistency will have clearly
been changed.

\item \textbf{Case 3:} $CAS_{append-inn}$ fails, which, by
\ref{lemma-cas2}, indicates that either some other thread has already completed
$CAS_{append-inn}$ with another element, or another consistency changing
instruction, $CAS_{seal}$ or $CAS_{foreach}$ has successfully completed.

\end{itemize}

Therefore, \verb=append= itself as well as all other operations reachable via an
invocation of \verb=append= are guaranteed to have a finite number of steps between
\textit{consistency} changing instructions.
\qed
\end{prooftwo}

%==============================
% LEMMA 6 (CAS5)
%==============================

% We don't actually cite this lemma? Really?

\begin{lemmatwo}[$CAS_{seal}$]\label{lemma-cas5}
After invoking \verb=seal(size)=, if $CAS_{seal}$ fails, then some thread has
successfully completed $CAS_{seal}$ or $CAS_{append-inn}$ after some finite number of steps.
\end{lemmatwo}

\begin{prooftwo} Since by \ref{lemma-cas2}, we know that $CAS_{append-out}$
only duplicates an existing $Terminal$, it can not be the cause for a failing
$CAS_{seal}$. This leaves only two cases in which $CAS_{seal}$ can fail:

\begin{itemize}
\item \textbf{Case 1:} Another thread has already completed $CAS_{seal}$.
\item \textbf{Case 2:} Another thread completes an invocation to the
$append(elem)$ operation after the current thread completes the read of
$currobj$. In this  case, $CAS_{seal}$ can fail because $CAS_{append-inn}$
might have  completed before, in which case, it inserts a new $Elem$ object
$elem$  into location $idx$.
\qed
\end{itemize}
\end{prooftwo}

%==============================
% Lemma \ref{lemma-write2-write3}, WRITE2 AND WRITE3
%==============================

\begin{lemmatwo}[$WRITE_{adv}$ and $WRITE_{seal}$]\label{lemma-write2-write3}
After updating $b.index$ using $WRITE_{adv}$ or $WRITE_{seal}$,  $b.index$ is guaranteed
to be incremented after a finite number of steps.
\end{lemmatwo}

\begin{prooftwo}
For some index, $idx$, both calls to $WRITE_{adv}$ and $WRITE_{seal}$ attempt
to write $idx+1$ to $b.index$. In both cases, it's possible that another
thread could complete either $WRITE_{adv}$ or $WRITE_{seal}$, once again
writing $idx$ to $b.index$ after the current thread has completed, in effect
overwriting the current thread's write with $idx+1$. By inspection of the
pseudocode, both $WRITE_{adv}$ and $WRITE_{seal}$ will be repeated if
$b.index$ has not been incremented. However, since the number of threads
operating on the FlowPool is finite, $p$, we are guaranteed that in the worst
case, this scenario can repeat at most $p$ times, before a write correctly
updates $b.index$ with $idx+1$.
\qed
\end{prooftwo}

%==============================
% Lemma \ref{lemma-finite-steps-consistency-change} (SEAL: FINITE # STEPS BEFORE CONSISTENCY CHANGE)
%==============================

\begin{lemmatwo}[Finite Steps Before Consistency Change]\label{lemma-finite-steps-consistency-change}
After invoking \verb=seal(size)=, a consistency changing instruction will be
completed after a finite number of steps, or the initial invocation of
\verb=seal(size)= completes.
\end{lemmatwo}

\begin{prooftwo}
The \verb=seal= operation can be restarted in two scenarios.

\begin{itemize}

\item \textbf{Case 1:} The check $idx \leq LASTELEMPOS$ succeeds, indicating
that we are at a valid location in the current block $b$, but the object at
the current index location $idx$ is of type $Elem$, not $Terminal$, causing a
recursive call to \verb=seal= with the same size $size$.

In this case, we begin by showing that the atomic write of $idx+1$ to
$b.index$, required to iterate through the block $b$ for the recursive call to
\verb=seal=, will be correctly incremented after a finite number of steps.

Therefore, by both the guarantee that, in a finite number of steps, $b.index$
will eventually be correctly incremented as we saw in
\ref{lemma-write2-write3}, as well as by $INV1$ we know that the original invocation of
\verb=seal= will correctly iterate through $b$ until a $Terminal$ is found.
Thus, we know that the call to \verb=tryWriteSeal= will be invoked, and by
both \ref{lemma-finite-steps-state-change} and \ref{lemma-append},
we know that either \verb=tryWriteSeal=, will successfully complete in a
finite number of steps, in turn successfully completing \verb=seal(size)=, or
$CAS_{append-inn}$, another consistency changing operation will successfully
complete.

\item \textbf{Case 2:} The check $idx \leq LASTELEMPOS$ fails, indicating that
we must move on to the next block, causing first a call to \verb=expand=
followed by a recursive call to \verb=seal= with the same size $size$.

We proceed by showing that after a finite number of steps, we must end up in
Case 1, which we have just showed itself completes in a finite number of
steps, or that a consistency change must've already occurred.

By \ref{lemma-expand}, we know that an invocation of \verb=expand=
returns after a finite number of steps, and $pool.current$ is updated to point
to a subsequent block.

If we are in the recursive call to \verb=seal=, and the $idx \leq LASTELEMPOS$
condition is $false$, trivally, a consistency changing operation must have
occurred, as, the only way for the condition to evaluate to $true$ is through
a consistency changing operation, in the case that a block has been created
during an invocation to \verb=append=, for example.

% In the case, where after the invocation $expand$, but before the read of $b$
% ($READ(pool.current)$) in the recursive call to \verb=seal=, we have that
% $current.index > LASTELEMPOS$, the a consistency change must have occurred.
% That is, another thread has already updated $pool.current$ by a different
% invocation to $expand$, which means that, in the meantime, an element has
% already been inserted via \verb=append=.

% Trivally, a consistency changing operation must have occurred, as, the only
% way for $current.index > LASTELEMPOS$ to evaluate to $true$ is if a block .

% % Thus, as the only way for the index to
% % change is via $WRITE1$ which occurs only if $CAS_{append-inn}$ succeeds, a consistency
% % changing instruction must have completed.

Otherwise, if we are in the recursive call to \verb=seal=, and the $idx \leq LASTELEMPOS$
condition evaluates to $true$, we enter Case 1, which we just
showed will successfully complete in a finite number of steps.

\end{itemize}
\qed
\end{prooftwo}

%==============================
% Lemma \ref{lemma-foreach-cons} (FOREACH: FINITE # STEPS BEFORE CONSISTENCY CHANGE)
%==============================

\begin{lemmatwo}[Foreach]\label{lemma-foreach-cons}
After invoking \verb=foreach(fun)=, a consistency changing instruction will
be completed after a finite number of steps.
\end{lemmatwo}

We omit the proof for \verb=foreach= since it proceeds in the exactly the same way
as does the proof for \verb=seal= in
\ref{lemma-finite-steps-consistency-change}.

%==============================
% Lemma \ref{lemma-operation-completes}
%==============================

\begin{lemmatwo}\label{lemma-operation-completes}
Assume some concurrent operation is started. If some thread completes
a consistency changing CAS instruction, then some concurrent operation is
guaranteed to be completed.
\end{lemmatwo}

\begin{prooftwo}
% By Lemma X and Y, we know that consistency changing
% instructions $CAS_{append-inn}$, $CAS_{seal}$, and $CAS_{foreach}$ are guaranteed to at some point
% complete.

By trival inspection of the pseudocode, if $CAS_{append-inn}$ successfully
completes on some thread, then that thread is guaranteed to complete the
corresponding invocation of \verb=append= in a finite number of steps.

% we don't say anything about WRITE1 here because it's guaranteed to succeed,
% so it's trivial.
\enlargethispage{\baselineskip}

Likewise by trivial inspection, if $CAS_{seal}$ successfully completes on some
thread, then by \ref{lemma-finite-steps-state-change},
\verb=tryWriteSeal= is guaranteed to complete in a finite number of steps, and
therefore, that thread is guaranteed to complete the corresponding invocation
of \verb=seal= in a finite number of steps.

The case for $CAS_{foreach}$ is omitted since it follows the same steps as for the case
of $CAS_{seal}$
\qed
\end{prooftwo}
